---
title:  "ELK + fileBeat를 이용한 로그 수집과 저장"
excerpt: "ELK와 fileBeat를 이용해 로그를 수집하고 저장해봅니다."

categories:
  - projects
tags:
  - ELK
  - nodejs
  - logging
last_modified_at: 2020-03-12T08:06:00-05:00
published : false
---

# ELK docker 설치

ElasticSearch, Kibana, Logstash의 도커 이미지를 다운받는다.

```sh
$ git clone https://github.com/deviantony/docker-elk.git
$ cd docker-elk
```

각 이미지마다 config 파일이 존재한다. 세부 설정은 이 파일을 수정하면 가능하다.

```
├── kibana
│   ├── Dockerfile
│   └── config
│       └── kibana.yml
└── logstash
    ├── Dockerfile
    ├── config
    │   └── logstash.yml
    └── pipeline
        └── logstash.conf
```

elasticsearch 를 싱글 노드에서 수행되도록 설정하자.

클러스터를 구성하고 싶다면, `docker-compose.yml` 파일에서 컨테이너를 여러 개 띄우면 된다.

```yaml
---
## Default Elasticsearch configuration from Elasticsearch base image.
## https://github.com/elastic/elasticsearch/blob/master/distribution/docker/src/docker/config/elasticsearch.yml

cluster.name: "docker-cluster"
network.host: 0.0.0.0

# minimum_master_nodes need to be explicitly set when bound on a public IP
# set to 1 to allow single node clusters
# Details: https://github.com/elastic/elasticsearch/pull/17288
# 노드 수 3개로 설정.
discovery.zen.minimum_master_nodes: 1
```

Logstash의 파이프라인은 `logstash.conf` 에서 설정 가능하다.

```conf
input {
	tcp {
		port => 5000
		codec => json_lines
	}
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "changeme"
	}
}
```

# ELK 실행

이제 ELK 이미지를 실행해보자.

```sh
$ docker-compose build && docker-compose up -d
```

5601 포트에서 Kibana가 정상 작동됨을 확인하자.

# Filebeat 설치

마찬가지로 Filebeat의 도커 이미지를 가져와서 실행해보자.

```sh
$ docker pull docker.elastic.co/beats/filebeat:7.6.1
```

설정 파일을 다운받아 수정해보자

````sh
$ curl -L -O https://raw.githubusercontent.com/elastic/beats/7.6/deploy/docker/filebeat.docker.yml
````

다운받은 설정파일 템플릿은 다음과 같다.

```yaml
filebeat.config:
  modules:
    path: ${path.config}/modules.d/*.yml
    reload.enabled: false

filebeat.autodiscover:
  providers:
    - type: docker
      hints.enabled: true

processors:
- add_cloud_metadata: ~

output.elasticsearch:
  hosts: '${ELASTICSEARCH_HOSTS:elasticsearch:9200}'
  username: '${ELASTICSEARCH_USERNAME:}'
  password: '${ELASTICSEARCH_PASSWORD:}'
```



