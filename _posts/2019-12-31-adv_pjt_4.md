---
title:  "고문헌 번역 프로젝트(4) - 웹서버 개발"
excerpt: "BOAZ ADV PROJECT - 웹서버 개발"

categories:
  - projects
tags:
  - BOAZ
  - project
  - web
  - flask
  - kubernetes
last_modified_at: 2019-12-31T09:06:00-05:00
---

> [고문헌 번역 프로젝트(2) - 첫번째 번역 모델](/projects/adv_pjt_2)
>
> [고문헌 번역 프로젝트(3) - Transformer:robot: 적용](/projects/adv_pjt_3)
>
> [GitHub Repository](https://github.com/getChan/ADV) :octocat:
>
> 모델도 거의 완성되었고, 번역기를 돌려볼수 있는 웹 서비스를 개발해보자.

# 소개

이전에 딥러닝 모델을 돌려볼수 있게끔 웹서비스를 개발해 본 적이 있었다. ([인터넷방송 유해도 산출을 통한 필터링 시스템](/projects/cyberaffity/))

모델이 크고 서버 성능이 좋지 않아 사용자 트래픽이 조금만 많아져도 서버가 꺼지는 문제가 많이 발생했었다. Flask로 개발했는데 당시에는 몰랐으나, Flask는 경량 프레임워크라 기본적으로 프로덕션 서버가 붙어있지 않다는 걸 모르고 그냥 개발용 서버로 배포해버려서 그랬던 것 같다.. 

아무튼! 이런 상황을 방지하기 위해서 이번에는 Flask에 프로덕션 서버 설치하고

Google Kubernetes Engine을 사용해서 

- 클라우드에서 Auto Scale-out 하고 
- Load Balancing 도 고려해서 개발해보려 한다.

웹 프레임워크로는 Flask 사용할 것이다.

- 딥러닝 모델은 연산이 무겁다
  - 경량 프레임워크인 Flask 사용해서 필요한 것만 남기자
- Flask는 Python 기반이다.
  - 텐서플로우 프레임워크와 호환이 비교적 자유롭다.

# Flask Web Server

Flask를 이용해 웹서버를 구축해보자.

> 대부분의 Flask 코드는 책 "깔끔한 파이썬 탄탄한 백엔드 (송은우 저)" 을 참고하여 작성했습니다.
>
> 굉장히 불친절한 코드 죄송합니다. 책과 깃허브를 참고해주세요

1. Flask 설치

2. 사용자의 요청을 받는 API 코드 작성

   ```python
   #app.py
   from flask import Flask, request, render_template
   import demo_run
   
   def create_app():
       app = Flask(__name__)
   
       @app.route('/', methods=['GET', 'POST'])
       def demo():
           if request.method == "POST":
               query = request.form.get('query')
               # model predict
               print(query)
               result = demo_run.translate(query)
               return render_template("demo.html", result=result, query=query)
           else:
               return render_template('demo.html')
           
       return app
   ```

   - 사용자의 입력을 input으로 하는 model predict 코드 작성

    ```
   자세한 코드는 [github 저장소](https://github.com/getChan/ADV/server/demo_run.py)를 참고
    ```

 3. 배포용 서버(Production Server)로 설정하여 배포

    - `flask-twisted` 와 `flask_script` 라이브러리 설치

    ```python
    #setup.py
    import sys
     
    from flask_script import Manager
    from app import create_app
    from flask_twisted import Twisted
    from twisted.python import log
     
    if __name__ == '__main__':
        app = create_app()
        twisted = Twisted(app)
        log.startLogging(sys.stdout)
     
        app.logger.info(f'Running the app...')
     
        manager = Manager(app)
        manager.run()
    ```

4. Server Run

   ```shell
   # 80번 포트로 서버 run
   # `nohub`은 현재 ssh 세션이 종료되어도 해당 명령어를 계속 실행시켜 준다
   # `&`은 프로세스를 background에서 실행한다.
   $ nohub python setup.py runserver --host=0.0.0.0 --port=80 &
   ```

# Docker Image 생성

kubernetes는 docker image를 가지고 container를 생성하여 동일한 서버 환경을 그대로 가져온다. 

우선적으로, 프로젝트에 필요한 Docker Image를 생성하여 docker hub에 push해보자.

> [Docker 참고 포스팅](/data/data_engineering_4/) /  [Kubernetes 참고 포스팅](https://getchan.github.io/data/data_engineering_5/)

## Base Image Pull

일단, [참고 문서](https://www.tensorflow.org/install/docker?hl=ko)를 따라서 텐서플로우 모델을 GPU상에서 실행할 수 있는 도커 이미지를 가져온다.

- 텐서플로우에서 tensorflow model GPU 연산을 쉽게 할 수 있는 Docker 이미지를 배포해두었다. 

- host server에 nvidia gpu driver만 있으면 CUDA 등의 설치 없이 도커 이미지만을 가지고 GPU 연산을 수행할 수 있는 도커 이미지이다.

- nvidia gpu driver는 GKE에서 자동으로 설치하는 Demon set을 제공한다. 따라서 드라이버를 따로 설치할 필요 없다.

```shell
$ docker pull tensorflow/tensorflow:latest-gpu-py3
# 가장 최신 이미지의 GPU연산과 python3를 지원하는 이미지 pull
```

`nvidia-docker` 컨테이너를 설치해야 컨테이너에서 nvidia-GPU를 사용할 수 있다고 한다. 설치해주자

```shell
$ docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi
```

가져온 이미지를 컨테이너로 실행하고 컨테이너에 진입해보자. 80번 포트는 컨테이너에 바인딩한다.

```shell
$ docker run --name adv-container -p 0.0.0.0:80:80 -it tensorflow/tensorflow:latest-gpu-py3 bash 
```

진입한 컨테이너에서 `apt-get` 을 업데이트하고, git을 설치후 서버 코드를 가져온다.

```shell
$ apt-get update 
$ apt-get install git
$ cd ~
$ git clone https://github.com/getChan/ADV
```

pip를 upgrade하고 필요한 패키지를 설치한다

```shell
$ pip install --upgrade pip
$ pip install -r requirements.txt
```

서버를 실행 후 잘 실행이 된다면, 만든 컨테이너를 새롭게 Image 파일로 만들어야 한다.

## Make Dockerfile









# Google Kubernetes Engine

GCP에서 Kubernetes Engine을 이용하려고 한다. (GKE)

> 운이 좋게도 Google Study Jam 자격증반에 참여하면서 Qwiklab 크레딧을 주고 한달간 실습할수 있게끔 해줘서 GCP console사용법을 익힐 수 있었다.
>
> 또한 [GKE GPU 가이드 문서](https://cloud.google.com/kubernetes-engine/docs/how-to/gpus?hl=ko&_ga=2.267977159.-832087542.1571376036&_gac=1.19746890.1577790248.Cj0KCQiAgKzwBRCjARIsABBbFuh7guv-Ow7tn55NT5cnDW-4_FcVEP6oO3pZlLxk_BfS1Qh9F_rkA_QaAmjBEALw_wcB#gpu_pool)가 아주 잘 설명되있어서 참고하여 구축하였다.

모델의 연산이 너무 커서 GPU가 설치된 서버 인스턴스가 필요했다. (GPU 제일 싼게 `0.4$ / hour` :sob:)

기본적으로 GPU 달린 인스턴스를 만들려면 제한된 할당량을 해제해줘야 한다.(디폴트로 GPU 0개 제한되어 있음)

할당량 해제 요청을 보내고 이틀 후 GPU 할당량이 1로 늘어나 있었다.







