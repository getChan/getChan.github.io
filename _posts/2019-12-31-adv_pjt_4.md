---
title:  "고문헌 번역 프로젝트(4) - 웹서버 개발"
excerpt: "BOAZ ADV PROJECT - 웹서버 개발"

categories:
  - projects
tags:
  - BOAZ
  - project
  - web
  - flask
  - kubernetes
last_modified_at: 2019-12-31T09:06:00-05:00
---

> [고문헌 번역 프로젝트(2) - 첫번째 번역 모델](/projects/adv_pjt_2)
>
> [고문헌 번역 프로젝트(3) - Transformer:robot: 적용](/projects/adv_pjt_3)
>
> [GitHub Repository](https://github.com/getChan/ADV) :octocat:
>
> 모델도 거의 완성되었고, 번역기를 돌려볼수 있는 웹 서비스를 개발해보자.

# 소개

이전에 딥러닝 모델을 돌려볼수 있게끔 웹서비스를 개발해 본 적이 있었다. [인터넷방송 유해도 산출을 통한 필터링 시스템](/projects/cyberaffity/)

모델이 크고 서버 성능이 좋지 않아 사용자 트래픽이 조금만 많아져도 서버가 꺼지는 문제가 많이 발생했었다. Flask로 개발했는데 당시에는 몰랐으나, Flask는 경량 프레임워크라 기본적으로 프로덕션 서버가 붙어있지 않다는 걸 모르고 그냥 개발용 서버로 배포해버려서 그랬던 것 같다.. 

아무튼! 이런 상황을 방지하기 위해서 이번에는 Flask에 프로덕션 서버 설치하고

Google Kubernetes Engine을 사용해서 

- 클라우드에서 Auto Scale-out 하고 
- Load Balancing 도 고려해서 개발해보려 한다.

웹 프레임워크로는 Flask 사용할 것이다.

- 딥러닝 모델은 연산이 무겁다
  - 경량 프레임워크인 Flask 사용해서 필요한 것만 남기자
- Flask는 Python 기반이다.
  - 텐서플로우 프레임워크와 호환이 비교적 자유롭다.

# Kubernetes

GCP에서 Kubernetes Engine을 이용하려고 한다. (GKE)

> 운이 좋게도 Google Study Jam 자격증반에 참여하면서 Qwiklab 크레딧을 주고 한달간 실습할수 있게끔 해줘서 GCP console사용법을 익힐 수 있었다.
>
> 또한 [GKE GPU 가이드 문서](https://cloud.google.com/kubernetes-engine/docs/how-to/gpus?hl=ko&_ga=2.267977159.-832087542.1571376036&_gac=1.19746890.1577790248.Cj0KCQiAgKzwBRCjARIsABBbFuh7guv-Ow7tn55NT5cnDW-4_FcVEP6oO3pZlLxk_BfS1Qh9F_rkA_QaAmjBEALw_wcB#gpu_pool)가 아주 잘 설명되있어서 참고하여 구축하였다.

모델의 연산이 너무 커서 GPU가 설치된 서버 인스턴스가 필요했다. (제일 싼게 `0.4$ / hour` :sob:)

기본적으로 GPU 달린 인스턴스를 만들려면 제한된 할당량을 해제해줘야 한다.(디폴트로 GPU 0개 제한되어 있음)

할당량 해제 요청을 보내고 이틀 후 GPU 할당량을 1로 늘려주었다.





