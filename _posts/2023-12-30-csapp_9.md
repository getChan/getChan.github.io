---
title: "CSAPP(9) - Virtual Memory"
excerpt: "Computer Systems : A Programmer’s Perspective - 7장"

categories:
  - cs
  - os
tags:
  - csapp
last_modified_at: 2023-12-30T08:00:00-08:00
---

메모리를 여러 프로세스가 공유하면 CPU사용량이 늘어나고 에러를 발생시킬 수 있다.
메모리를 효율적으로 사용하고 에러를 줄이기 위해 현대 시스템은 virtual memory라는 가상 메모리 추상화를 제공한다.
가상 메모리는 커널 소프트웨어가 각 프로세스에게 제공하는 크고, 균일하고, 개인적인 주소 공간이다.

가상 메모리의 능력
- 메모리를 디스크에 저장된 주소 공간의 캐시처럼 사용.
  - 활성화된 영역만 메모리에 올린다.
- 메모리 관리의 단순화
  - 각 프로세스에 균일한 주소 공간을 제공
- 각 프로세스의 주소 공간이 충돌하지 않도록 보호

# 1. Physical and Virtual Addressing
CPU가 물리 주소를 사용하여 메모리의 접근하는 방식을 물리 어드레싱이라 한다.

현대 프로세스는 가상 어드레싱을 사용한다.

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yTK1-G_UOlbgW9zJ)
- 주소 변환 : 가상 주소를 물리 주소로 바꾸는 것
  - Memory Management Unit(MMU)는 CPU칩 내에 있으며, OS에 의해 관리되는 룩업 테이블(메모리에 존재)를 사용해서 변환

# 2. Address Spaces
각 데이터 개체는 여러 독립적인 주소를 가진다.
- 메모리의 각 바이트는 가상 주소 공간의 가상 주소와 물리 주소 공간의 물리 주소를 가진다.

# 3. VM as a Tool for Caching
개념적으로, 가상 메모리는 디스크에 있는 N개의 연속된 바이트 크기 셀의 배열로 구성된다.
- 각 바이트는 고유한 가상 주소를 갖고, 이게 배열의 인덱스다.
- 디스크 내 배열의 내용은 메모리에 캐시된다
  - 디스크의 데이터는 블락이라는 단위로 쪼개져 메모리로 전송된다. VM 시스템은 가상 메모리를 virtual page라는 고정 크기 블락으로 쪼갠다. 물리 메모리 또한 physical page로 쪼갠다.

가상 페이지 집합은 세개로 나뉜다.
- *Unallocated* : VM에 의해 할당되지 않은 페이지. 데이터도 없고, 디스크 공간을 점유하지 않음
- *Cached* : 물리 메모리에 캐시된 페이지.
- *Uncached* : 물리 메모리에 캐시되지 않은 패이지.

## 3.1. DRAM Cache Organication
DRAM 캐시란 VM 시스템의 가상 페이지를 말한다. 
- DRAM 캐시 미스는 SRAM 미스에 비해 비용이 크다(속도가 느리다)
- 페널티가 크기 때문에 가상 페이지는 크다. (4KB~2MB) 또한 같은 이유로 write-through 대신 write-back을 사용한다.(쓰기 연산을 미룬다.)

## 3.2. Page Tables
다른 캐시와 마찬가지로 물리 메모리에서 victim page를 선택하고, 디스크에서 DRAM으로 가상 페이지를 복제하는 등의 작업이 필요하다. 이러한 기능은 OS 소프트웨어와 MMU(메모리 관리 유닛) 내 주소 변환 하드웨어, 페이지 테이블이라 하는 물리 메모리에 저장된 자료구조의 조합으로 구성된다.
- 주소 변환 하드웨어는 페이지 테이블을 읽어서 가상 주소를 물리 주소로 변환한다.
- os는 페이지 테이블을 관리하고 페이지를 disk과 DRAM사이에 전달한다.

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gtxRP1TX7KFzK41r)
- 유효 비트가 설정되면, 주소 필드는 물리 페이지 시작 주소를 가르킨다.
- 유효 비트가 설정되지 않고
  - null 주소이면, 가상 페이지가 할당되지 않았다.
  - 이외의 경우, 주소는 디스크의 가상 페이지 시작 주소를 가르킨다.

## 3.4. Page Faults
1. 주소 변환 하드웨어는 메모리에서 페이지 테이블을 조회
2. 유효 비트를 통해 캐시되지 않음을 확인
3. 페이지 폴트 예외를 발생
4. 커널의 페이지 폴트 핸들러를 호출
   1. 핸들러는 희생 페이지를 선택
   2. 희생 페이지가 수정되었다면 disk에 복사(write-back)
   3. 페이지 테이블 업데이트
   4. 디스크의 가상 페이지를 물리 페이지로 복사
   5. 페이지 테이블 업데이트
5. 폴트 명령을 재수행
   1. 캐시됨을 확인
   2. 페이지 히트. 주소 변환 하드웨어의 정상 수행

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*925IP60PCIJALWRy)


## 3.6. Locality to the Rescue Again
지역성 덕분에 가상 메모리는 꽤 잘 동작한다.

활성 페이지가 물리 메모리의 크기를 초과하면 thrashing 현상이 발생한다.
- 페이지가 연속해서 swap-in/out

# 4. VM as a Tool for Memory Management
가상 메모리는 메모리 관리와 보호를 쉽게 만든다.
- 요구 페이징과 분리된 가상 주소 공간의 조합을 이용해
- 링킹, 로딩, 코드와 데이터 공유, 애플리케이션 메모리 할당을 쉽게 한다.

os는 각 프로세스에 분리된 페이지 테이블을 제공하여 분리된 가상 주소 공간을 제공한다.
- 동일한 물리 페이지를 공유한다.

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6BdbyT-4Xb3Q62jK)

- 단순한 링킹 : 분리된 주소 공간은 각 프로세스가 동일한 메모리 이미지 형태를 갖게 한다. 이는 링커가 물리 메모리의 코드와 데이터 위치와 독립적인 완전 링크된 실행파일을 쉽게 만들 수 있게 한다.
- 단순한 로딩 : 목적 파일 내 `.text`와 `.data` 영역을 로드하기 위해, 리눅스 로더는 가상 페이지를 할당하고 not cached로 표시한다. 또한 페이지 테이블 엔트리를 목적 파일을 가리키도록 한다. **로더는 절대 디스크의 데이터를 메모리로 복사하지 않는다. vm에 의해서만 자동으로 요구시에 복사된다.**
  - 이러한 연속된 가상 페이지 집합을 임의의 파일 위치에 매핑하는 것을 *memory mapping*이라 한다.
  - 각 응용 프로그램이 고유의 메모리 맵을 가진다.
- 단순한 공유 : OS는 여러 프로세스가 하나의 코드 복제본을 공유하도록 한다. (커널, 표준 C 라이브러리 등)
- 단순한 메모리 할당 : 동적 메모리 할당을 할 때, os가 인접한 물리 페이지를 찾을 필요가 없다. 페이지는 물리 메모리에 흩어져 있다.

# 5. VM as a Tool for Memory Protection
유저 프로세스에게 허용되지 않아야 할 것들
- 읽기 전용 코드 영역 수정
- 커널의 코드나 자료구조를 읽거나 수정
- 다른 프로세스의 메모리를 읽거나 수정
- 다른 프로세스와 공유하는 가상 페이지를 수정
  - 모든 프로세스가 허용하지 않는 경우

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qeEuKSPrxRAMyKbt)

페이지 테이블에 허용 비트를 추가해 구현
- `SUP` : 커널 모드에만 접근 허용
- 특정 명령이 허용을 위반하면 CPU는 보호 폴트를 발생시킨다. 커널의 예외 핸들러는 제어를 넘겨받아서 프로세스에게 `SIGSEGV` 시그널을 보낸다. (segmentation fault)

# 6. Address Translation

페이지 히트 시 CPU 하드웨어의 수행 단계
1. 프로세스는 가상 주소를 생성해 MMU에 보낸다.
2. MMU는 PTE(page table entry) 주소를 생성하고 캐시/메인 메모리에 요청한다.
3. 캐시/메모리는 PTE 주소를 MMU에 반환
4. MMU는 물리 주소를 구성하고 캐시/메모리에 요청한다.
5. 캐시/메모리는 요청 데이터 워드를 프로세서에 반환한다.

![](https://img2018.cnblogs.com/blog/1521884/201811/1521884-20181110125534029-117982038.png)

페이지 폴트 시에는 하드웨어와 OS커널의 협력이 필요하다.
1. 위의 1~3과 동일
2. PTE의 유효 비트가 0이면 MMU는 CPU로부터 커널의 페이지 폴트 예외 핸들러로 제어를 전달하는 예외를 발생시킨다.
3. 폴트 핸들러는 물리 메모리 내 희생 페이지를 식별하고, 그 페이지가 이전에 수정되었다면 디스크에 쓴다.
4. 폴트 핸들러는 새 페이지를 메모리로 가져온 뒤, 메모리의 PTE를 갱신한다.
5. 기존 프로세스에 제어를 반환한다. CPU는 가상 주소를 MMU에 재전송하고 페이지 히트 과정을 거친다

![](https://img2018.cnblogs.com/blog/1521884/201811/1521884-20181110125534292-1921098612.png)

많은 시스템에서 가상 메모리와 SRAM 캐시를 같이 사용하는데, 대부분은 물리 주소를 캐시한다.

**TLB로 주소 변환 속도 증가**
- TLB(transition lookaside buffer)란 MMU내에 있는 페이지 테이블의 캐시
- 작은 가상 주소 캐시

![](https://img2018.cnblogs.com/blog/1521884/201811/1521884-20181110125534788-1959995409.png)

**멀티 레벨 페이지 테이블**

페이지 테이블은 꽤 크고 메모리에 전체가 상주하는 것은 비효율적이다. 멀티 레벨 페이지 테이블은 이 문제를 해결한다.

다단계 페이지 테이블 구조는 다음 방법으로 메모리 사용량을 줄인다.
1. 레벨 1 테이블에 PTE가 null이면 다음 단계의 테이블은 존재할 필요가 없다.
2. 레벨 1 테이블만 메모리에 상주하고 다음 단계의 테이블은 스왑 아웃할 수 있다. 자주 사용되는 테이블만 메모리에 캐시할 수 있다.

멀티 레벨 구조가 느릴 것 같지만, TLB가 다른 레벨의 PTE를 캐시하는 것을 통해 단일 레벨 페이지 테이블과 유사한 속도를 보인다.

# 7. The Intel Core i7 / Linux Memory System
> 필요할 때 자세히 보기

# 8. Memory Mapping


